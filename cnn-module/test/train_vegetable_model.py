import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
import happybase
from v2.vegetable_dataset import VegetableDataset
from v2.vegetable_model import VegetableCNN

import matplotlib.pyplot as plt

# è®¾ç½®matplotlibçš„ä¸­æ–‡å­—ä½“ä¸ºæ¥·ä½“ï¼Œè§£å†³ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif']=['Simsun']
# è®¾ç½®matplotlibçš„è´Ÿå·æ­£å¸¸æ˜¾ç¤ºï¼Œé¿å…è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—
plt.rcParams['axes.unicode_minus']=False

def load_all_samples(host="cluster1", port=9090, table_name="vegetable_image_data"):
    """
    ä» HBase è¡¨ä¸­æ‰«ææ‰€æœ‰æ ·æœ¬ï¼Œå¹¶è‡ªåŠ¨æ„å»º label_to_idx æ˜ å°„ã€‚

    è¿”å›:
        row_keys: æ‰€æœ‰æ ·æœ¬çš„ row key (å­—ç¬¦ä¸²åˆ—è¡¨)
        labels:   æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„æ ‡ç­¾å­—ç¬¦ä¸²
        label_to_idx: æ ‡ç­¾åˆ°ç±»åˆ« ID çš„æ˜ å°„å­—å…¸
    """
    conn = happybase.Connection(host=host, port=port)
    table = conn.table(table_name)

    row_keys = []
    labels = []
    unique_labels = set()

    # æ‰«ææ‰€æœ‰è¡Œï¼Œä»…è·å– meta:label åˆ—ä»¥æé«˜æ•ˆç‡
    for key, data in table.scan(columns=[b"meta:label"]):
        label = data[b"meta:label"].decode("utf-8")
        unique_labels.add(label)
        row_keys.append(key.decode("utf-8"))
        labels.append(label)

    conn.close()

    # æŒ‰å­—æ¯é¡ºåºæ’åºï¼Œä¿è¯æ˜ å°„ä¸€è‡´æ€§å’Œå¯å¤ç°æ€§
    sorted_labels = sorted(unique_labels)
    label_to_idx = {label: idx for idx, label in enumerate(sorted_labels)}

    return row_keys, labels, label_to_idx


# --- ä¸»ç¨‹åºå¼€å§‹ ---

# 1. è‡ªåŠ¨ä» HBase åŠ è½½æ•°æ®å¹¶æ„å»ºç±»åˆ«æ˜ å°„
print("æ­£åœ¨ä» HBase åŠ è½½æ•°æ®å¹¶è‡ªåŠ¨æ„å»ºç±»åˆ«æ˜ å°„...")
all_keys, all_labels, LABEL_TO_IDX = load_all_samples()

print("æ£€æµ‹åˆ°çš„ç±»åˆ«æ˜ å°„:")
for label, idx in LABEL_TO_IDX.items():
    print(f"  {label} -> {idx}")

IDX_TO_LABEL = {v: k for k, v in LABEL_TO_IDX.items()}
num_classes = len(LABEL_TO_IDX)
print(f"å…± {num_classes} ä¸ªç±»åˆ«\n")

# 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆ80%è®­ç»ƒï¼Œ20%æµ‹è¯•ï¼‰
# ä½¿ç”¨ stratify=all_labels ç¡®ä¿å„ç±»åˆ«æ¯”ä¾‹åœ¨è®­ç»ƒ/æµ‹è¯•é›†ä¸­ä¸€è‡´
train_keys, test_keys, train_labels, test_labels = train_test_split(
    all_keys, all_labels, test_size=0.2, random_state=42, stratify=all_labels
)

# 3. å®šä¹‰å›¾åƒé¢„å¤„ç†å’Œæ•°æ®å¢å¼º
# è®­ç»ƒé›†ï¼šåŒ…å«æ•°æ®å¢å¼º
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),  # ç»Ÿä¸€è¾“å…¥å°ºå¯¸
    transforms.RandomHorizontalFlip(),  # éšæœºæ°´å¹³ç¿»è½¬ï¼Œå¢å¼ºæ³›åŒ–
    transforms.ToTensor(),  # è½¬ä¸º [0,1] å¼ é‡
    # ImageNet é¢„è®­ç»ƒæ¨¡å‹çš„æ ‡å‡†åŒ–å‚æ•°ï¼Œåˆç†å¤ç”¨
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# æµ‹è¯•é›†ï¼šä»… Resize å’Œ Normalizeï¼Œä¸å¢å¼º
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 4. åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
train_dataset = VegetableDataset(
    row_keys=train_keys,
    labels=train_labels,
    label_to_idx=LABEL_TO_IDX,
    transform=train_transform
)
test_dataset = VegetableDataset(
    row_keys=test_keys,
    labels=test_labels,
    label_to_idx=LABEL_TO_IDX,
    transform=test_transform
)

# 5. åˆ›å»º DataLoader
# batch_size=16ï¼šåˆç†ï¼Œå†…å­˜å‹å¥½
# shuffle=Trueï¼šè®­ç»ƒæ—¶æ‰“ä¹±
# num_workers=0ï¼šåœ¨ Windows æˆ–æŸäº›ç¯å¢ƒä¸­é¿å…å¤šè¿›ç¨‹é—®é¢˜ï¼Œç”Ÿäº§ç¯å¢ƒå¯è®¾ä¸º >0
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)

print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")

# 6. åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
model = VegetableCNN(num_classes=num_classes)
# Adam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 0.001ï¼Œweight_decay=1e-4 é˜²æ­¢è¿‡æ‹Ÿåˆ
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
# CrossEntropyLossï¼šé€‚ç”¨äºå¤šåˆ†ç±»ï¼Œè¾“å…¥ä¸º logitsï¼ˆæœªå½’ä¸€åŒ–ï¼‰ï¼Œæ­£ç¡®
loss_fn = nn.CrossEntropyLoss()


# 7. å®šä¹‰è¯„ä¼°å‡½æ•°
def evaluate(model, loader):
    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    correct = 0
    total = 0
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
        for images, labels in loader:
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)  # è·å–é¢„æµ‹ç±»åˆ«
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return correct / total  # è¿”å›å‡†ç¡®ç‡


# 8. è®­ç»ƒè¿‡ç¨‹ï¼ˆå¸¦æ—©åœæœºåˆ¶ï¼‰
EPOCHS = 100
best_acc = 0.0
patience = 20  # æ—©åœè€å¿ƒå€¼
patience_counter = 0

print("\nå¼€å§‹è®­ç»ƒ...\n")

for epoch in range(EPOCHS):
    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()  # æ¢¯åº¦æ¸…é›¶
        outputs = model(images)  # å‰å‘ä¼ æ’­
        loss = loss_fn(outputs, labels)  # è®¡ç®—æŸå¤±
        loss.backward()  # åå‘ä¼ æ’­
        optimizer.step()  # æ›´æ–°å‚æ•°
        # ç´¯è®¡æŸå¤±ï¼ˆåŠ æƒå¹³å‡ï¼‰
        running_loss += loss.item() * images.size(0)

    # è®¡ç®—æ•´ä¸ª epoch çš„å¹³å‡æŸå¤±
    epoch_loss = running_loss / len(train_dataset)
    # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡
    test_acc = evaluate(model, test_loader)

    print(f"è½®æ¬¡(Epoch) {epoch + 1}/{EPOCHS} - æŸå¤±å€¼(Loss): {epoch_loss:.4f} - æµ‹è¯•å‡†ç¡®ç‡(Test Acc): {test_acc:.4f}")

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if test_acc > best_acc:
        best_acc = test_acc
        torch.save(model.state_dict(), "../CNN_Vegetable_Model_best.pt")
        patience_counter = 0
        print(f"âœ… æ–°æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼Œå‡†ç¡®ç‡: {best_acc:.4f}")
    else:
        patience_counter += 1

    # æ—©åœåˆ¤æ–­
    if patience_counter >= patience:
        print(f"â¹ï¸ æ—©åœè§¦å‘ï¼Œè¿ç»­ {patience} ä¸ª epoch æ²¡æœ‰æå‡")
        break

print(f"\nè®­ç»ƒå®Œæˆï¼æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.4f}")

# è®­ç»ƒç»“æŸåï¼ŒåŠ è½½æœ€ä½³æ¨¡å‹å†è¯„ä¼°ä¸€æ¬¡
model.load_state_dict(torch.load("../CNN_Vegetable_Model_best.pt", weights_only=False))
final_acc = evaluate(model, test_loader)
print(f"âœ… æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_acc:.4f}")

# ==============================
# ğŸš€ å¯¼å‡ºæ¨¡å‹ä¸º ONNX æ ¼å¼
# ==============================

import torch.onnx

# 1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
device = torch.device("cpu")  # ONNX é€šå¸¸ç”¨ CPU å¯¼å‡ºï¼Œé¿å… GPU å¼ é‡é—®é¢˜
model = VegetableCNN(num_classes=num_classes)
state_dict = torch.load("../CNN_Vegetable_Model_best.pt", weights_only=True, map_location=device)
model.load_state_dict(state_dict)
model.eval()  # eval æ¨¡å¼ï¼

# 2. åˆ›å»ºä¸€ä¸ª dummy inputï¼ˆæ¨¡æ‹ŸçœŸå®è¾“å…¥ï¼‰
# æ³¨æ„ï¼šå°ºå¯¸å¿…é¡»å’Œè®­ç»ƒæ—¶ä¸€è‡´ (batch_size=1, channels=3, height=224, width=224)
dummy_input = torch.randn(1, 3, 224, 224, device=device)

# 3. å¯¼å‡ºä¸º ONNX
onnx_file_path = "../vegetable_classifier.onnx"
torch.onnx.export(
    model,
    dummy_input,
    onnx_file_path,
    export_params=True,  # å­˜å‚¨è®­ç»ƒå¥½çš„å‚æ•°
    opset_version=13,  # ONNX ç®—å­é›†ç‰ˆæœ¬ï¼ˆæ¨è 11~17ï¼Œ13 å…¼å®¹æ€§å¥½ï¼‰
    do_constant_folding=True,  # ä¼˜åŒ–å¸¸é‡
    input_names=['input'],  # è¾“å…¥åï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    output_names=['output'],  # è¾“å‡ºåï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    dynamic_axes={
        'input': {0: 'batch_size'},  # åŠ¨æ€ batch ç»´åº¦
        'output': {0: 'batch_size'}
    }
)

print(f"âœ… æ¨¡å‹å·²æˆåŠŸå¯¼å‡ºä¸º ONNX æ ¼å¼: {onnx_file_path}")
